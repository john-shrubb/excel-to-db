from openpyxl import load_workbook, Workbook
from psycopg2 import connect
from custom_types.connection_details import ConnectionDetails
from custom_types.data_type import DataType
from datetime import datetime

# When initialised, treat ExcelToDB like a cursor.

class ExcelToDB:
	def __init__(self, file_path : str, db_conn_details : ConnectionDetails):
		self.file_path = file_path
		self.db_conn_details = db_conn_details
		self.column_types : dict[str, DataType] = {}
		try:
			self.__connection__ = connect(
				host=db_conn_details.host,
				port=db_conn_details.port,
				database=db_conn_details.database,
				user=db_conn_details.user,
				password=db_conn_details.password
			)
		except Exception as e:
			raise Exception(f'Error connecting to database\n{e}')

		try:
			self.wb : Workbook = load_workbook(file_path)
		except Exception as e:
			raise Exception(f'Error loading workbook\n{e}')
	
	def get_column_names(self) -> list[str]:
		'''
		Returns the column names of the active sheet in the workbook.
		'''
		active = self.wb.active

		if not active:
			raise TypeError('No active sheet found.')

		columns = active.iter_rows(min_row=1, max_row=1, values_only=True)

		to_return : list[str] = []

		for column in columns:
			for col in column:
				to_return.append(str(col))
		
		return to_return
	
	def insert_column_types(self, data_types : list[DataType]):
		'''
		After the column names have been retrieved, the user can now insert the column types (Assuming use in a CLI context).

		:param data_types: A list of the data types. Can be inserted in any order.
		'''

		column_names = self.get_column_names()

		for data_type in data_types:
			if (data_type.table_column_name not in column_names):
				raise ValueError(f'Column name {data_type.table_column_name} not found in the active sheet.')
			self.column_types[data_type.table_column_name] = data_type
		
		if len(self.column_types) != len(column_names):
			raise ValueError('Not all column types have been inserted.')
	
	def generate_sql(self, table_name : str) -> list[str]:
		'''
		Generates an SQL query to populate a table.
		'''

		active = self.wb.active

		if not active:
			raise TypeError('No active sheet found.')
		
		statements = []
		for row_number in range(2, active.max_row + 1):
			# Key: DB Column Name
			# Value: Value to insert
			to_insert: dict[str, str | int | float | datetime] = {}

			# For each column, get the value in that row.
			for column_number in range(1, active.max_column + 1):
				column_name = str(active.cell(row=1, column=column_number).value)

				# Get data type

				data_type = self.column_types[column_name]

				# Add the value to the dictionary.

				to_insert[data_type.db_column_name] = data_type.parse(str(active.cell(row=row_number, column=column_number).value))
			
			# Generate the SQL statement.

			statement = f'INSERT INTO {table_name} ({', '.join(to_insert.keys())}) VALUES ({', '.join(['%s'] * len(to_insert.values()))});'

			# Use the connection to "mogrify" the statement.

			statement = self.__connection__.cursor().mogrify(statement, list(to_insert.values())).decode('utf-8')

			# Append the statement to the list of statements.

			statements.append(statement)
		
		self.statements : list[str] = statements
		return statements
	
	def execute_sql(self):
		'''
		Executes the SQL statements generated by generate_sql.
		'''

		# Get statements and ensure they do exist.
		statements = self.statements

		# If not then raise an error.
		if not statements:
			raise ValueError('No statements to execute.')

		# Execute each statement.
		for statement in statements:
			self.__connection__.cursor().execute(statement)
		
		# And commit the changes.
		self.__connection__.commit()

if __name__ == '__main__':
	print('This is part of a library and should not be run directly.')
	exit(1)